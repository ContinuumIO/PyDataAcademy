{
 "metadata": {
  "name": "etl_basics"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "ETL Basics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Author: [Continuum Analytics](http://continuum.io)\n",
      "* Author: Stefan Urbanek\n",
      "\n",
      "\n",
      "Objective of this tutorial is to learn basics of ETL and to prepare simple star schema for aggregated browsing with Cubes. Data source is denormalized table, originally stored in a CSV file.\n",
      "\n",
      "All transformations and data preparation is being done purely in Python. SQL library is used only for storing the data in a relational database. Note that some cells might contain intentionally faulty code. Read following cells for more information about the error.\n",
      "\n",
      "\n",
      "Skills gained:\n",
      "\n",
      "* working with CSV file\n",
      "* working with database schema (creation and deletion of tables)\n",
      "* loading of data into a database\n",
      "* data transformations\n",
      "* normalization\n",
      "* surroage keys (basics)\n",
      "* how to make process reproducible and extensible\n",
      "* how to maintain data provenance\n",
      "\n",
      "Required knowledge:\n",
      "\n",
      "* relational database basics\n",
      "* regular expression bacisc\n",
      "\n",
      "Other requirements:\n",
      "\n",
      "* [sqlalchemy](http://www.sqlalchemy.org) - SQL/relational database framework\n",
      "\n",
      "**Utility functions:**\n",
      "\n",
      "* `distinct(rows, column)` - get distinct values of a column from list of rows\n",
      "* `transform(row, transformation, index_map)` - transforms row according to transformation (see the module)\n",
      "\n",
      "Data\n",
      "----\n",
      "\n",
      "* Source: [World Bank](https://finances.worldbank.org/Procurement/Major-Contract-Awards-FY2010-FY2012-Beta-version/kdui-wcs3)\n",
      "* File name: `Major_Contract_Awards_FY2010_-_FY2012_-_Beta_version.csv`\n",
      "* Date of download: 2012-10-11\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Introduction\n",
      "============\n",
      "\n",
      "Imagine we are building an analytical application for ad-hoc reporting of awarded contract awards from World Bank. The original dataset we have received is in a form of a single file with following fields:\n",
      "\n",
      "* As of Date\n",
      "* Fiscal Year\n",
      "* Region\n",
      "* Borrower Country\n",
      "* Borrower Country Code\n",
      "* Project ID\n",
      "* Project Name\n",
      "* Procurement Type,\n",
      "* Procurement Category\n",
      "* Procurement Method\n",
      "* Product line\n",
      "* WB Contract Number\n",
      "* Major Sector\n",
      "* Contract Description\n",
      "* Contract Signing Date\n",
      "* Supplier\n",
      "* Supplier Country\n",
      "* Supplier Country Code\n",
      "* Total Contract Amount (USD)\n",
      "\n",
      "Requirements and expectations are:\n",
      "\n",
      "1. this is just initial dataset, we might get more in the future\n",
      "2. we might have more information in the future about involved entities, such as supliers or countries\n",
      "3. the application is going to have web interface and raw data API\n",
      "\n",
      "Uncertainities that we have to be ready for:\n",
      "\n",
      "1. we are not sure that the datasets in the future will have the same structure\n",
      "2. we are not sure that the dataset in the future will be in one denormalized (\"wide\") table\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Preparation\n",
      "===========\n",
      "\n",
      "*Note: see python package requirements of this module before you start executing example statements.*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "import re\n",
      "import sqlalchemy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Specify the file name we are interested in for processing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filename = \"data/Major_Contract_Awards_FY2010_-_FY2012_-_Beta_version.csv\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Structure"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Even we were told what files the file contains, we rather not trust the information and verify it by ourselves. The information might be outdated, might be just copied from other sources without actual valiation.\n",
      "\n",
      "We start by looking at the structure of the source file and try to answer following very basic questions:\n",
      "\n",
      "* what kind of text file it is?\n",
      "* Does it contain a header with field names?\n",
      "* What are the fields?\n",
      "\n",
      "Even we have assumptions about the source file, we have to verify them. Let's start by reading first five lines of the file:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(filename) as f:\n",
      "    for i, line in enumerate(f):\n",
      "        print line\n",
      "        if i >= 5:\n",
      "            break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We learned that:\n",
      "\n",
      "1. file contains header row:\n",
      "\n",
      "    `As of Date,Fiscal Year,Region,Borrower Country,Borrower Country Code,Project ID,Project Name,Procurement Type,Procurement Category,Procurement Method,Product line,WB Contract Number,Major Sector,Contract Description,Contract Signing Date,Supplier,Supplier Country,Supplier Country Code,Total Contract Amount (USD)`\n",
      "\n",
      "2. file is composed of comma `','` separated values\n",
      "3. some fields are quoted by double quote as in: `\"Agriculture, fishing, and forestry\"`\n",
      "\n",
      "This information is sufficient for the time being to be able to load the file with a `csv` (comma separated values) reader from [`csv`](http://docs.python.org/2/library/csv.html) Python module:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(filename) as f:\n",
      "    reader = csv.reader(f)\n",
      "    header = reader.next()\n",
      "header"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We see that the header contains quite descriptive labels of the columns and they seem to be the same as given by our requestor for the task.\n",
      "\n",
      "Despite some databases support arbirtary column names, we should not have this assumtion. Therefore we need column names that look like identifiers. If we have just a few columns, we might do that manually, in our case we can create a simple function that will help us to convert the names into identifiers by replacing all non-identifier characters into underscores `'_'`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def string_to_ident(astring):\n",
      "    return re.sub(\"[^\\w]\", \"_\", astring.lower())\n",
      "string_to_ident('Borrower Country Code')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that you are very likely not going to use this function in automated environment, but might be helpful when dealing with number of uknown data sources that you need to process."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "File Contents Analysis"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Objectives:** \n",
      "\n",
      "1. identify categories (future dimensions) and their keys\n",
      "2. If there are no natural keys, generate ones.\n",
      "3. create mapping tables or mapping functions between original values and keys"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we read the file or sample of the file together with headers. We assume that the file sample contains all code values that will ever be available in potential subsequent additions to the dataset (such as project type codes or region codes).\n",
      "\n",
      "**Note:** In real world environment it is quite commont that we will work with files that will not fit whole in the memory and we will have to either sample them or analyse them differently. For managing distinct values there will be a more complex process which we are not going to describe at this point."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read file header and all the rows\n",
      "with open(filename) as f:\n",
      "    reader = csv.reader(f)\n",
      "    header = reader.next()\n",
      "    rows = list(reader)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We generate field names as proposed previously, using our string-to-identifier helper conversion function:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fields = [string_to_ident(f) for f in header]\n",
      "fields"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Field/column names were generated quite nicely. Just small correction for the last field name:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fields[-1] = \"total_contract_amount\"\n",
      "fields"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Normalization"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's have a look at the file contents. We see that it contains multiple categories or dimensions:\n",
      "\n",
      "* fiscal year\n",
      "* region\n",
      "* borrower country\n",
      "* project\n",
      "* procurement\n",
      "* sector\n",
      "* supplier\n",
      "\n",
      "Those categories are composed of multiple values, for example the *procurement* has three attributes: *type*, *category* and *method*.\n",
      "\n",
      "One of our original requirements was, that we might get more information about the entities in the future. Therefore we have to extract the entities into separate table - to normalize it:\n",
      "\n",
      "![](files/images/normalize.png)\n",
      "\n",
      "For normalization we need to:\n",
      "\n",
      "1. understand dimensions and their values - how many attributes describe one dimension? how many different values?\n",
      "2. identify keys and generate custom keys if keys do not exist\n",
      "\n",
      "Keys\n",
      "----\n",
      "\n",
      "In this tutorial we are going to use keys that are derived from source data to maintain understandability of the process.\n",
      "\n",
      "We start with dimension regions. What values the column contains?\n",
      "\n",
      "**Excercise 1: get all distinct values of column 'region', which has index 2:**\n",
      "\n",
      "Inputs: `rows` contains all rows from our imput file as a list."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Excercise 1: get all distinct values of column 'region':\n",
      "# ..."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Solution for Excercise 1:**\n",
      "\n",
      "Easy way how to get a sorted list of distinct values of a field:\n",
      "\n",
      "1. get all values of the field\n",
      "2. collect the values in a `set()`\n",
      "3. convert the set to a list and sort it with `.sort()`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get distinct values of region column\n",
      "distinct_values = set(row[2] for row in rows)\n",
      "\n",
      "# Make it a list, so we can order it, as set is unordered container structure:\n",
      "regions = list(distinct_values)\n",
      "regions.sort()\n",
      "regions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There is no other attribute for regions in the source table. That means that regions do not have a key, so we generate one for them. We have just a few values, so we might create keys manually. However, we are going to generate them automatically. There are many possibilities, we might try for example taking the first letter of each word:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "region = 'LATIN AMERICA AND CARIBBEAN'\n",
      "words = region.split()\n",
      "first_letters = [word[0] for word in words]\n",
      "key =  \"\".join(first_letters)\n",
      "\n",
      "print \"region       : '%s'\" % region\n",
      "print \"words        : %s\" % (words, )\n",
      "print \"first letters: %s\" % first_letters\n",
      "print \"key          : '%s'\" % key"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Looks fine. Create a function for key creation and try it for all regions:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def region_code(region):\n",
      "    \"\"\"Create a key from first letters of words\"\"\"\n",
      "    return \"\".join([c[0] for c in region.split()])\n",
      "\n",
      "[region_code(region) for region in regions]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Rows of a dimension table for region will contain columns: `key` and `name`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dim_region = [(region_code(region), region) for region in regions]\n",
      "\n",
      "for row in dim_region:\n",
      "    print row"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Excercise:** change region names to be capitalized words. Create and use a function to do that."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have data for our dimension table and we have new keys. To be able to join tables together, we need how the original values map to the keys, therfore we create a mapping dictionary:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "region_map = dict((region, region_code(region)) for region in regions)\n",
      "region_map"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Before we proceed to our next dimension, remember how we created distinct values of region:\n",
      "\n",
      "    distinct_values = set(row[2] for row in rows)\n",
      "\n",
      "Note the `row[2]` - we have rows as lists, but we want to reference them by column names. We can convert our dataset to a list of dictionary objects, however in some cases this is much more memory intensive than storing just rows of values. Other option is to create a map between column name and field index. It will require a bit of more writing, but will prevent possible errors of using wrong field indexes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create a mapping between field name and column index\n",
      "findex = dict( (field, i) for i, field in enumerate(fields) )\n",
      "findex"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next one is \"Procurement Types\". We want to see the contents of the field - distinct values. To not to repeat ourselves again, we create a function for that.\n",
      "\n",
      "**Excercise: ** create a function that will take a list of rows and will return a sorted list of distinct values for given column index:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def distinct(rows, column):\n",
      "    \"\"\"Return sorted list of distinct values of alist:\"\"\"\n",
      "    pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Solution:**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def distinct(rows, column):\n",
      "    \"\"\"Return sorted list of distinct values of alist:\"\"\"\n",
      "    values = list(set(row[column] for row in rows))\n",
      "    values.sort()\n",
      "    return values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "proc_types = distinct(rows, findex[\"procurement_type\"])\n",
      "proc_types"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Quick and simple solution would be to get first three letters from each word. Not the nicest one but works fine:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "value = \"Raw Materals, Chemicals, Commodities\"\n",
      "print value\n",
      "\n",
      "value = value.upper()\n",
      "print value\n",
      "\n",
      "\n",
      "# remove non-identifier characters\n",
      "value = re.sub(\"[^\\w]+\", \" \", value)\n",
      "print value\n",
      "\n",
      "# split to words:\n",
      "words = value.split()\n",
      "print words\n",
      "\n",
      "# get first three letters\n",
      "values = [word[:3] for word in words]\n",
      "print values\n",
      "\n",
      "# merge back together\n",
      "key = \"\".join(values)\n",
      "print key"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define the function:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_code(value):\n",
      "    value = re.sub(\"[^\\w]+\", \" \", value.upper())\n",
      "    return \"\".join([word[:3] for word in value.split()])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is how the list looks like:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[create_code(pt) for pt in proc_types]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we look at the procurement category values:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "proc_categories = distinct(rows, findex[\"procurement_category\"])\n",
      "proc_categories"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are only few of them, we either create manual dictionary or can get first word. Create codes for procurement category:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "value = 'Civil Works'\n",
      "print \"value: '%s'\" % value\n",
      "\n",
      "words = value.split()\n",
      "print \"words: %s\" % (words, )\n",
      "\n",
      "print \"first: '%s'\" % words[0]\n",
      "\n",
      "key = words[0].upper()\n",
      "print \"key  : '%s'\" % key"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Looks fine, create a function for that:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def first_word_key(value):\n",
      "    \"\"\"Returns capitalized first word\"\"\"\n",
      "    return value.split()[0].upper()\n",
      "\n",
      "first_word_key('Civil Works')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Procurement method values:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "proc_methods = distinct(rows, findex[\"procurement_method\"])\n",
      "proc_methods"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can use for codes the `create_code()` function, it looks that it might fit our data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[create_code(pt) for pt in proc_methods]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dim_procurement_method = [(create_code(method), method) for method in proc_methods]\n",
      "dim_procurement_method"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "procurement_method_map = dict((method, create_code(method)) for method in proc_methods)\n",
      "procurement_method_map"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have three attributes of a procurement and their respective keys:\n",
      "    \n",
      "* procurement type\n",
      "* procurement category\n",
      "* procurement method\n",
      "\n",
      "If we look at the category and type we can see that they are in a hierarchical relationship. We can see that by getting a distinct values of both:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mdistinct(rows, columns):\n",
      "    \"\"\"Return sorted list of distinct values of alist:\"\"\"\n",
      "    values = list(set(tuple(row[column] for column in columns) for row in rows))\n",
      "    values.sort()\n",
      "    return values\n",
      "\n",
      "mdistinct(rows, [findex[\"procurement_category\"], findex[\"procurement_type\"]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That means that we are going to have two dimensions: *procurement type (and category)* and *procurement method*:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dim_procurement_type = []\n",
      "\n",
      "# Get distinct values of both attributes\n",
      "distinct_values = mdistinct(rows, [findex[\"procurement_category\"], findex[\"procurement_type\"]])\n",
      "\n",
      "for proc_category, proc_type in distinct_values:\n",
      "    row = [first_word_key(proc_category),\n",
      "           proc_category,\n",
      "           create_code(proc_type),\n",
      "           proc_type\n",
      "           ]\n",
      "    dim_procurement_type.append(row)\n",
      "    \n",
      "for row in dim_procurement_type:\n",
      "    print row"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In star schema, we are going to join the dimension table only by one key. We have to create one artificial \u2013 surrogate, that will represent a combination of the two keys of dimension attributes:\n",
      "\n",
      "![](files/images/surrogate_key.png)\n",
      "\n",
      "The key can be generated just from a simple integer sequence:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dim_procurement_type = []\n",
      "\n",
      "# Get distinct values of both attributes\n",
      "distinct_values = mdistinct(rows, [findex[\"procurement_category\"], findex[\"procurement_type\"]])\n",
      "\n",
      "surrogate_key = 1\n",
      "\n",
      "for proc_category, proc_type in distinct_values:\n",
      "    row = [surrogate_key,\n",
      "           first_word_key(proc_category),\n",
      "           proc_category,\n",
      "           create_code(proc_type),\n",
      "           proc_type\n",
      "           ]\n",
      "    surrogate_key += 1\n",
      "    dim_procurement_type.append(row)\n",
      "    \n",
      "print \"first 10 rows:\"\n",
      "for row in dim_procurement_type[:10]:\n",
      "    print row"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In our original table we have verbose labels and we need to get the same key for attribute combination as in the dimension table. For that purpose we create a mapping between source table attribute values and newly created surrogate key.\n",
      "\n",
      "**Excercise:** create a dictionary where key will be a tuple containing a tuple of `(procurement_category, procurement_type)` and value will contain the surrogate key:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Define procurement type map here:\n",
      "procurement_type_map = None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Solution:**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "procurement_type_map = {}\n",
      "\n",
      "KEY_COLUMN = 0\n",
      "CATEGORY_COLUMN = 2\n",
      "TYPE_COLUMN = 4\n",
      "\n",
      "for row in dim_procurement_type:\n",
      "    key = (row[CATEGORY_COLUMN], row[TYPE_COLUMN])\n",
      "    procurement_type_map[key] = row[KEY_COLUMN]\n",
      "    \n",
      "for key, value in procurement_type_map.items():\n",
      "    print \"%s ==> %s\" % (key, value)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Last dimension we are missing is sector:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sectors = distinct(rows, findex[\"major_sector\"])\n",
      "sectors"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can reuse `create_code()` to generate sector codes:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dim_sector = [(create_code(s), s) for s in sectors]\n",
      "dim_sector"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sector_map = dict((sector, create_code(sector)) for sector in sectors)\n",
      "sector_map"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Loading of Dimensions\n",
      "=====================\n",
      "\n",
      "We have data for dimensions ready, now we load them into dimension tables.\n",
      "\n",
      "Before we start, we have to prepare our database connection engine and metadata:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sqlalchemy\n",
      "engine = sqlalchemy.create_engine(\"sqlite:///data.sqlite\")\n",
      "metadata = sqlalchemy.MetaData(bind=engine)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Create tables"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "table = sqlalchemy.Table('dim_region', metadata)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "table.append_column(sqlalchemy.Column(\"key\", sqlalchemy.String))\n",
      "table.append_column(sqlalchemy.Column(\"name\", sqlalchemy.String))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "metadata.create_all()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Prepare an insert statement:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "insert = table.insert()\n",
      "str(insert)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Insert dimension values into the table:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for row in dim_region:\n",
      "    engine.execute(insert.values(row))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Check the table contents:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for row in table.select().execute():\n",
      "    print row"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As we are going to have multiple dimension tables and we do not want to repeat ourselves, we can create some utility functions for dimension table loading.\n",
      "\n",
      "What information we have about dimension tables?\n",
      "\n",
      "* list of attributes\n",
      "* types of attributes\n",
      "* dimension data\n",
      "\n",
      "First thing we need to do is to create the dimension table.\n",
      "\n",
      "**Excercise:** create a function `create_table(name, fields)` where `name` is dimension table name, `fields` is list of tuples: `(field_name, field_type)`. The `field_type` might be one of following string values: `\"integer\"`, `\"float\"` or `\"string\"`. You can expect global variables `engine` and `metadata` to be present.\n",
      "\n",
      "Hint: See the [SQLAlchemy types](http://docs.sqlalchemy.org/en/rel_0_7/core/types.html) for actual type objects that SQLAlchemy expects to be passed for table columns.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_table(name, fields):\n",
      "    # code here ...\n",
      "    pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Solution:**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_table(name, fields):\n",
      "    type_map = {\n",
      "                    \"integer\": sqlalchemy.Integer,\n",
      "                    \"string\": sqlalchemy.String,\n",
      "                    \"float\": sqlalchemy.Float\n",
      "                }\n",
      "\n",
      "    table = sqlalchemy.Table(name, metadata, autoload=False)\n",
      "    if table.exists():\n",
      "        print \"dropping existing table %s\" % name\n",
      "        table.drop()\n",
      "        metadata.drop_all(engine, tables=[table])\n",
      "        metadata.remove(table)\n",
      "\n",
      "    table = sqlalchemy.Table(name, metadata, autoload=False, keep_existing=False)\n",
      "\n",
      "    for field_name, field_type in fields:\n",
      "        column = sqlalchemy.Column(field_name, type_map[field_type])\n",
      "        table.append_column(column)\n",
      "        \n",
      "    print \"creating dimension table %s (columns: %s)\" % (name, [c.name for c in table.columns])\n",
      "    \n",
      "    table.create()\n",
      "    metadata.create_all(engine, tables=[table])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "create_table(\"dim_region\", [(\"key\", \"string\"), (\"name\", \"string\")])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To create all dimension tables, we define metadata of all our dimensions:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dimensions = [\n",
      "    {\"name\":\"dim_region\", \"fields\": [(\"key\", \"string\"), (\"name\", \"string\")]},\n",
      "    {\"name\":\"dim_procurement_type\", \"fields\": [(\"key\", \"string\"),\n",
      "                                            (\"category_code\", \"string\"),\n",
      "                                            (\"category_name\", \"string\"),\n",
      "                                            (\"type_code\", \"string\"),\n",
      "                                            (\"type_name\", \"string\")]},\n",
      "    {\"name\":\"dim_procurement_method\", \"fields\": [(\"key\", \"string\"), (\"name\", \"string\")]},\n",
      "    {\"name\":\"dim_sector\", \"fields\": [(\"key\", \"string\"), (\"name\", \"string\")]}\n",
      "]\n",
      "\n",
      "for dim in dimensions:\n",
      "    print \"DIMENSION %s\" % dim[\"name\"]\n",
      "    for field in dim[\"fields\"]:\n",
      "        print \"    %s (%s)\" % field"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create all dimension tables:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for dim in dimensions:\n",
      "    create_table(dim[\"name\"], dim[\"fields\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Load Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have empty tables prepared, now we load data into them as we did for region previously.\n",
      "\n",
      "**Excercise:** create a function `load_dimension_table(name, data)` that will load rows into the dimension table. You can assume that global variable `engine` and `metadata` exist."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_dimension_table(name, data):\n",
      "    # ...\n",
      "    pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_dimension_table(name, data):\n",
      "    print \"loading into dimension table %s\" % name\n",
      "    table = sqlalchemy.Table(name, metadata, autoload=False)\n",
      "    insert = table.insert()\n",
      "    for row in data:\n",
      "        engine.execute(insert.values(row))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "load_dimension_table(\"dim_region\", dim_region)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Update our metadata with references to acutal data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dimensions = [\n",
      "    {\n",
      "        \"name\":\"dim_region\",\n",
      "        \"fields\": [(\"key\", \"string\"), (\"name\", \"string\")],\n",
      "        \"data\": dim_region\n",
      "    },\n",
      "    {\n",
      "        \"name\":\"dim_procurement_type\",\n",
      "        \"fields\": [(\"key\", \"string\"),\n",
      "                    (\"category_code\", \"string\"),\n",
      "                    (\"category_name\", \"string\"),\n",
      "                    (\"type_code\", \"string\"),\n",
      "                    (\"type_name\", \"string\")],\n",
      "        \"data\": dim_procurement_type\n",
      "    },\n",
      "    {\n",
      "        \"name\":\"dim_procurement_method\",\n",
      "        \"fields\": [(\"key\", \"string\"), (\"name\", \"string\")],\n",
      "        \"data\": dim_procurement_method\n",
      "    },\n",
      "    {\n",
      "        \"name\":\"dim_sector\",\n",
      "        \"fields\": [(\"key\", \"string\"), (\"name\", \"string\")],\n",
      "        \"data\": dim_sector\n",
      "    }\n",
      "]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load data for all dimension tables:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for dim in dimensions:\n",
      "    load_dimension_table(dim[\"name\"], dim[\"data\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Utility Function: load_dimensions\n",
      "---------------------------------\n",
      "\n",
      "Create a utility function `load_dimensions(dimensions)` that takes a list of dimension metadata. Each list element is a dictionary with keys:\n",
      "\n",
      "* `name` - dimension table name\n",
      "* `fields` - list of tuples representing table columns with elements `(field_name, field_type)`\n",
      "* `data` - list of dimension rows (might be any iterable object)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_dimensions(dimensions):\n",
      "    # ...\n",
      "    pass\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Solution:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_dimensions(dimensions):\n",
      "    print \"creating and loading %d dimensions\" % len(dimensions)\n",
      "    for dim in dimensions:\n",
      "        create_table(dim[\"name\"], dim[\"fields\"])\n",
      "        load_dimension_table(dim[\"name\"], dim[\"data\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "load_dimensions(dimensions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now go to the folder where you have started this notebook and look for `data.sqlite` file. Open it and see if you will get same output:\n",
      "\n",
      "\tsqlite> .tables\n",
      "\tdim_procurement_method  dim_region            \n",
      "\tdim_procurement_type    dim_sector \n",
      "\tsqlite> .schema\n",
      "\tCREATE TABLE dim_procurement_method (\n",
      "\t\t\"key\" VARCHAR, \n",
      "\t\tname VARCHAR\n",
      "\t);\n",
      "\tCREATE TABLE dim_procurement_type (\n",
      "\t\t\"key\" VARCHAR, \n",
      "\t\tcategory_code VARCHAR, \n",
      "\t\tcategory_name VARCHAR, \n",
      "\t\ttype_code VARCHAR, \n",
      "\ttype_name VARCHAR\n",
      "\t);\n",
      "\tCREATE TABLE dim_region (\n",
      "\t\t\"key\" VARCHAR, \n",
      "\t\tname VARCHAR\n",
      "\t);\n",
      "\tCREATE TABLE dim_sector (\n",
      "\t\t\"key\" VARCHAR, \n",
      "\t\tname VARCHAR\n",
      "\t);"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pwd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Transformation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We are going to move contents of the CSV source file into a fact table with following structure:\n",
      "\n",
      "![](files/images/target_fact.png)\n",
      "\n",
      "\n",
      "To create the target table with desired structure and contents we have to perform certain transformations:\n",
      "\n",
      "* just copy source column into target without a change\n",
      "* ignore some source columns\n",
      "* derive new columns from source columns\n",
      "\n",
      "what we want to do is described in the following image:\n",
      "\n",
      "![](files/images/transformation.png)\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fact_fields = [\n",
      "                       (\"fiscal_year\", \"integer\"),\n",
      "                       (\"region_code\", \"string\"),\n",
      "                       (\"procurement_type_key\", \"string\"),\n",
      "                       (\"procurement_method_code\", \"string\"),\n",
      "                       (\"major_sector_code\", \"string\"),\n",
      "                       (\"contract_amount\", \"float\")\n",
      "                ]\n",
      "create_table(\"fact_contracts\", fact_fields)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have our data as list of anonymous rows. While it is good from data processing perspective, it is not practical in our current situation where we would like to try our transformations. We can use sample of our data and transform it into a dictionary so we can refer to values by their field names:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#first\n",
      "record = dict(zip(fields, rows[0]))\n",
      "record"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create sample fact record as a dictionry (for the time being):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fact = {}\n",
      "fact[\"fiscal_year\"] = record[\"fiscal_year\"]\n",
      "fact"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Add the region code. Remember we have region codes in the `region_map` dictionry. Region for the sample record is `\"SOUTH ASIA\"`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "region_map[\"SOUTH ASIA\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The record will be:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fact[\"region_code\"] = region_map[record[\"region\"]]\n",
      "fact"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Similar for procurement method and for sector:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fact[\"procurement_method_code\"] = procurement_method_map[record[\"procurement_method\"]]\n",
      "fact[\"sector_code\"] = sector_map[record[\"major_sector\"]]\n",
      "fact"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To get a surrogate key for procurement type we have to use two columns: `procurement_type` and `procurement_category`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type_tuple = (record[\"procurement_category\"], record[\"procurement_type\"])\n",
      "procurement_type_map[type_tuple]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can verify if this is ok by looking into the dimension table:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "table = sqlalchemy.Table(\"dim_procurement_type\", metadata, autoload=True)\n",
      "select = table.select().where(\"key = 24\")\n",
      "print \"type tuple: %s\" % (type_tuple, )\n",
      "print \"dimension values: %s\" % (engine.execute(select).fetchone(), )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Looks ok."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fact[\"procurement_type_key\"] = procurement_type_map[(record[\"procurement_category\"], record[\"procurement_type\"])]\n",
      "fact"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Last value to be transformed is the amount:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fact[\"contract_amount\"] = record[\"total_contract_amount\"]\n",
      "fact"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can now transform all our records.\n",
      "\n",
      "**Exercise:** transform all records in `rows` into a list named `facts` using previously defined transformations. Display first five transformed fact records."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "facts = []\n",
      "\n",
      "for row in rows:\n",
      "    # transformation code here ...\n",
      "    pass\n",
      "\n",
      "facts[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Solution:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "facts = []\n",
      "\n",
      "for row in rows:\n",
      "    record = dict(zip(fields, row))\n",
      "\n",
      "    fact[\"fiscal_year\"] = record[\"fiscal_year\"]\n",
      "    fact[\"region_code\"] = region_map[record[\"region\"]]\n",
      "    fact[\"procurement_method_code\"] = procurement_method_map[record[\"procurement_method\"]]\n",
      "    fact[\"sector_code\"] = sector_map[record[\"major_sector\"]]\n",
      "    fact[\"procurement_type_key\"] = procurement_type_map[(record[\"procurement_category\"], record[\"procurement_type\"])]\n",
      "    fact[\"contract_amount\"] = record[\"total_contract_amount\"]\n",
      "    \n",
      "    facts.append(fact)\n",
      "    \n",
      "facts[0:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can now insert those facts into fact table. We won't for the time being ...\n",
      "\n",
      "We will often need to do transformations of more tables. If you look at the previous transformation loop you can see a simple pattern in construction of the target fact record:\n",
      "\n",
      "* assignment of a value from existing field in a field of same (`fiscal_year`) or different name (`contract_amount`)\n",
      "* assignment of a value from a map where key is one or more fields in the source table\n",
      "\n",
      "We might add one more transformation, not mentioned here, but quite common:\n",
      "\n",
      "* assignment of a value that is result of a function that takes one or more fields from the source table as arguments\n",
      "\n",
      "We can describe a transformation in generic way as a function that takes a record to be transformed and transformation rules:\n",
      "\n",
      "![](files/images/transformation_function.png)\n",
      "\n",
      "For each type of transformation we need name of target field, list of source fields, type of operation and operation specification. For example:\n",
      "\n",
      "    fact[\"fiscal_year\"] = record[\"fiscal_year\"]\n",
      "\n",
      "Target field: `fiscal_year`, source field(s): `fiscal_year` (the same), operation: copy field. No detailed specification necessary.\n",
      "\n",
      "\n",
      "    fact[\"contract_amount\"] = record[\"total_contract_amount\"]\n",
      "\n",
      "Target field: `contract_amount`, source field(s): `total_contract_amount`, operation: copy field. No detailed specification necessary.\n",
      "\n",
      "    fact[\"region_code\"] = region_map[record[\"region\"]]\n",
      "\n",
      "Target field: `region_code`, source field(s): `region`, operation: map using `region_map` dictionary.\n",
      "\n",
      "Etc.\n",
      "\n",
      "We have identified operations: `copy`, `map` and `function` therefore mapping can be described as a dictionary:\n",
      "\n",
      "    {\n",
      "        \"source\": \"region\",\n",
      "        \"operation\": \"map\",\n",
      "        \"map\": region_map\n",
      "    }\n",
      "\n",
      "And we can assign such transformation to each target field, for example as a tuple `(target, transformation)`:\n",
      "\n",
      "    transformations = [\n",
      "        (\"fiscal_year\", {\"source\":\"fiscal_year\", \"operation\": None}),\n",
      "        (\"region\", {\"source\":\"region\", \"operation\":\"map\", \"map\":\"region_map\"})\n",
      "        ...\n",
      "    ]\n",
      "\n",
      "We can simplify the transformation in a way that when copy of a field is desired and the target field is named the same as source field then we just do not provide the transformation - we provide `None` transformation:\n",
      "\n",
      "    transformations = [\n",
      "        (\"fiscal_year\", None),\n",
      "        (\"region\", {\"source\":\"region\", \"operation\":\"map\", \"map\":\"region_map\"})\n",
      "        ...\n",
      "    ]\n",
      "\n",
      "Now we have a nice way how to describe the transformations. We can even skip the `\"operation\"` key and perform operation based on presence of `mapping` or `function` (for the time being, ignore fact that we can have both specified at the same time):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "transformations = [\n",
      "        (\"fiscal_year\",             None),\n",
      "        (\"region_code\",             {\"source\":\"region\",\n",
      "                                     \"mapping\":region_map}),\n",
      "        (\"procurement_method_code\", {\"source\":\"procurement_method\",\n",
      "                                     \"mapping\":procurement_method_map}),\n",
      "        (\"sector_code\",             {\"source\":\"major_sector\",\n",
      "                                     \"mapping\":sector_map}),\n",
      "        (\"procurement_type_key\",    {\"source\":[\"procurement_category\", \"procurement_type\"],\n",
      "                                     \"mapping\":procurement_type_map}),\n",
      "        (\"contract_amount\",         {\"source\":\"total_contract_amount\"}),\n",
      "        \n",
      "]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Order of target fields is given by the transformation list. As our transformation fucntion receives an anonymous row as input, we need to know indices of input fields. Therefore the transformation function requires one more piece of information (metadata): either list of fields to generate indices or directly indices.\n",
      "\n",
      "Exercise: create a function that returns a dictionary mapping indices of fields"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def field_index_map(fields):\n",
      "    # create the index map\n",
      "    pass\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Solution:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def field_index_map(fields):\n",
      "    # create the index map\n",
      "    return dict( (field, i) for i, field in enumerate(fields) )\n",
      "field_index_map(fields)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we have everything we need to create our more complex, but generic transformation function.\n",
      "\n",
      "\n",
      "Note: to understand this function, following Python knowledge is required: functions as object, expanding function argument list from a list, querying instance type of an object (`isinstance`) to check if an object is a string."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def transform(row, transformation, index_map):\n",
      "    \"\"\"Transforms `row` using `transformation`.\"\"\"\n",
      "    result = []\n",
      "\n",
      "    for (target_field, action) in transformation:\n",
      "        if not action:\n",
      "            # Just copy value if no action is specified\n",
      "            value = row[index_map[target_field]]\n",
      "        else:\n",
      "            source = action[\"source\"]\n",
      "            if isinstance(source, basestring):\n",
      "                # Create a single element tuple of values\n",
      "                value = row[index_map[source]]\n",
      "\n",
      "                if \"function\" in action:\n",
      "                    value = action[\"function\"](value)\n",
      "                if  \"mapping\" in action:\n",
      "                    value = action[\"mapping\"].get(value)\n",
      "            else:\n",
      "                # Create a tuple of source values\n",
      "                values = tuple(row[index_map[field]] for field in source)\n",
      "                if \"function\" in action:\n",
      "                    value = action[\"function\"](*values)\n",
      "                if  \"mapping\" in action:\n",
      "                    value = action[\"mapping\"].get(values)\n",
      "\n",
      "        # Append value to result        \n",
      "        result.append(value)\n",
      "        \n",
      "    return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Transform sample rows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indices = field_index_map(fields)\n",
      "\n",
      "facts = []\n",
      "\n",
      "for row in rows[:5]:\n",
      "    facts.append(transform(row, transformations, indices))\n",
      "    \n",
      "facts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load\n",
      "====\n",
      "\n",
      "Fact table is transformed, now we have to load the data into database:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "facts_table = sqlalchemy.Table(\"fact_contracts\", metadata, autoload=True)\n",
      "\n",
      "insert = facts_table.insert()\n",
      "\n",
      "for row in rows[:5]:\n",
      "    engine.execute(insert.values(transform(row, transformations, indices)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What? We have a `StatementError: could not convert string to float: $4454652.00`. Problem is, that our `contract_amount` column is a float, but the source value is a string with currency symbol. Create a transformation function to fix that problem:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def currency_to_float(value):\n",
      "    try:\n",
      "        return float(value.strip('$'))\n",
      "    except ValueError:\n",
      "        return None\n",
      "\n",
      "currency_to_float('$4454652.00')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "... and fix the transformation (`contract_amount` is the last column):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "transformations[-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "transformations[-1] = ('contract_amount', {\"function\":currency_to_float, \"source\": 'total_contract_amount'})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Check:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "transform(rows[0], transformations, indices)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we are fine, last value is a number, not a string. Try to load again"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "facts_table = sqlalchemy.Table(\"fact_contracts\", metadata, autoload=True)\n",
      "\n",
      "insert = facts_table.insert()\n",
      "\n",
      "for row in rows[:5]:\n",
      "    engine.execute(insert.values(transform(row, transformations, indices)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Check the loaded data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cursor = engine.execute(facts_table.select())\n",
      "for i, row in enumerate(cursor):\n",
      "    print row\n",
      "    if i >= 10:\n",
      "        break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Appendix: Provenance"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Thanks to meta-data based definition of our transformation, we now know how we got the result fields from. If the data were stored separately, just as some ETL configuration file, then one does not need to even look at source code to be able to do that. That means, that it does not require programming skills to trace origin of fields:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for target, action in transformations:\n",
      "    if action:\n",
      "        source = action[\"source\"]\n",
      "        if \"mapping\" in action:\n",
      "            operation = \"using mapping\"\n",
      "        elif \"funciton\" in action:\n",
      "            operation = \"using function\"\n",
      "        else:\n",
      "            operation = \"copying\"\n",
      "    else:\n",
      "        operation = \"copying\"\n",
      "        source = target\n",
      "        \n",
      "    print \"field %s comes from %s by %s\" % (target, source, operation)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}